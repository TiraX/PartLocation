# 需求文档

## 引言

本项目旨在创建一个深度学习模型工程，用于从2D图像输入预测3D空间中各部件的相对位置、旋转和缩放参数。该模型接收**整体图像**和**部件图像**作为输入（均支持单视图或多视图），输出部件相对于整体的3D变换参数（Position, Rotation, Scale），使得部件能够在3D空间中正确放置到整体模型的对应位置。

### 核心输入输出定义

**输入：**
1. **整体图片**（1张图像）：
   - 单视图模式：仅包含前视图
   - 3视图模式：包含前视图 + 其他2个视图（左/右/后中选2个）
   - 4视图模式：包含前、后、左、右四个视图
   - **前视图为必备视图**
   
2. **部件图片**（1张图像）：
   - 单视图模式：仅包含前视图
   - 3视图模式：包含3个视角
   - 4视图模式：包含4个视角
   - **部件图片与整体图片中的某部分在语义上对应，但不是像素级完全对应**

**输出：**
- 平移（Translation）：3D向量 [tx, ty, tz]
- 旋转（Rotation）：四元数 [qw, qx, qy, qz] 
- 缩放（Scale）：3D向量 [sx, sy, sz]

### 技术选型
- 采用当前最先进的视觉基础模型（如 **DINOv2**、**DINOv3** 等）作为图像特征提取器
- 利用预训练模型的强大语义理解能力处理"语义对应但非像素对应"的挑战

### 应用场景示例
输入：
- 整体图片：人物4视图图像（前后左右拼接在一张图中）
- 部件图片：头部4视图图像

输出：头部相对于整体的变换参数
- 位置：[0, 0.2, 1.6]
- 旋转：[1, 0, 0, 0]（四元数，表示无旋转）
- 缩放：[0.23, 0.23, 0.23]

---

## 需求

### 需求 1：输入数据处理

**用户故事：** 作为一名深度学习工程师，我希望系统能够灵活处理不同视图配置的输入图像，以便适应各种数据来源和应用场景。

#### 验收标准

1. WHEN 输入整体图片为单视图 THEN 系统 SHALL 正确识别并处理单张前视图图像
2. WHEN 输入整体图片为3视图 THEN 系统 SHALL 正确分割并处理3个视角的子图像，其中前视图为必备视图
3. WHEN 输入整体图片为4视图 THEN 系统 SHALL 正确分割并处理前、后、左、右4个视角的子图像
4. WHEN 输入部件图片 THEN 系统 SHALL 支持与整体图片相同的视图配置（单视图/3视图/4视图）
5. IF 整体图片和部件图片的视图数量不一致 THEN 系统 SHALL 能够处理混合配置（如整体4视图+部件单视图）
6. WHEN 解析多视图图片 THEN 系统 SHALL 自动检测视图排列方式（水平排列/网格排列）或通过配置指定

---

### 需求 2：特征提取与语义匹配

**用户故事：** 作为一名机器学习研究员，我希望利用最先进的视觉基础模型提取图像特征，以便准确建立部件与整体之间的语义对应关系。

#### 验收标准

1. WHEN 提取图像特征 THEN 系统 SHALL 使用预训练的视觉基础模型（DINOv2/DINOv3等）作为特征提取器
2. WHEN 处理多视图输入 THEN 系统 SHALL 对每个视图独立提取特征，然后进行多视图特征融合
3. WHEN 建立语义对应 THEN 系统 SHALL 通过特征匹配而非像素匹配来关联部件与整体
4. IF 使用DINOv2 THEN 系统 SHALL 支持ViT-S/14、ViT-B/14、ViT-L/14、ViT-g/14等不同规模的模型
5. WHEN 进行特征融合 THEN 系统 SHALL 采用交叉注意力机制实现整体特征与部件特征的有效交互
6. IF 预训练模型需要微调 THEN 系统 SHALL 支持冻结骨干网络或端到端微调两种模式

---

### 需求 3：模型架构设计

**用户故事：** 作为一名深度学习工程师，我希望有一个能够处理多视图输入并输出精确变换参数的网络架构，以便准确预测部件在3D空间中的位置。

#### 验收标准

1. WHEN 设计编码器 THEN 模型 SHALL 采用双流架构：整体编码器和部件编码器（可共享权重）
2. WHEN 处理多视图 THEN 模型 SHALL 包含视图聚合模块，将多个视角的特征融合为统一表示
3. WHEN 融合整体与部件特征 THEN 模型 SHALL 使用交叉注意力模块捕捉语义对应关系
4. WHEN 预测变换参数 THEN 模型 SHALL 输出10个参数：
   - 平移：[tx, ty, tz]（3个参数）
   - 旋转：[qw, qx, qy, qz]（4个参数，四元数）
   - 缩放：[sx, sy, sz]（3个参数）
5. WHEN 输出旋转参数 THEN 模型 SHALL 确保四元数输出经过归一化处理
6. IF 需要支持不同视图配置 THEN 模型 SHALL 使用位置编码或视图类型编码区分不同视角

---

### 需求 4：数据准备与合成数据生成

**用户故事：** 作为一名数据工程师，我希望有完整的数据生成和预处理流程，以便为模型训练提供高质量的多视图训练数据。

#### 4.1 数据源规范

1. WHEN 导入3D模型 THEN 系统 SHALL 支持 **FBX 格式**作为主要数据源
2. WHEN 解析FBX文件 THEN 系统 SHALL 自动识别并提取模型内部已划分的 **sections（部件）**
3. IF FBX模型包含多个section THEN 系统 SHALL 能够遍历所有section并单独处理每个部件

#### 4.2 整体模型归一化

1. WHEN 处理整体模型 THEN 系统 SHALL 将整体模型归一化到 **[-0.5, 0.5]** 的立方体空间内
2. WHEN 执行归一化 THEN 系统 SHALL 采用**一致性缩放**（Uniform Scaling），即XYZ三个轴使用相同的缩放因子
3. WHEN 计算缩放因子 THEN 系统 SHALL 以模型最大边界维度为基准，确保模型完全落入归一化空间
4. WHEN 归一化 THEN 系统 SHALL 保留一定的 **padding空间**（例如实际占用[-0.45, 0.45]），避免模型紧贴边界
5. WHEN 归一化 THEN 系统 SHALL 记录归一化参数（原始中心点、缩放因子）以便后续使用

#### 4.3 部件归一化与变换参数计算

1. WHEN 处理每个section部件 THEN 系统 SHALL 将部件**单独**归一化到 **[-0.5, 0.5]** 空间
2. WHEN 归一化部件 THEN 系统 SHALL 同样采用一致性缩放和padding
3. WHEN 计算变换参数 THEN 系统 SHALL 计算**归一化后的部件**相对于**归一化后的整体**的：
   - 平移（Translation）：部件中心在整体坐标系中的位置
   - 旋转（Rotation）：部件相对于整体的旋转（四元数）
   - 缩放（Scale）：部件归一化后相对于整体归一化后的缩放比例
4. WHEN 记录变换参数 THEN 系统 SHALL 确保：
   - 平移值范围合理（通常在[-1, 1]之间，因为整体已归一化到[-0.5, 0.5]）
   - 缩放值表示部件相对整体的大小比例

#### 4.4 数据验证机制

1. WHEN 完成数据生成 THEN 系统 SHALL **自动执行验证流程**
2. WHEN 验证数据 THEN 系统 SHALL 执行以下步骤：
   - 加载各部件的归一化模型
   - 根据计算出的transform参数（平移、旋转、缩放）对各部件进行变换
   - 将变换后的部件拼合成完整模型
   - 渲染拼合后的模型图像
3. WHEN 比较验证图像 THEN 系统 SHALL 对比：
   - 拼合模型的渲染图 vs 整体模型的渲染图
4. IF 两张渲染图差异过大 THEN 系统 SHALL：
   - 标记该样本为**数据合成错误**
   - 输出错误日志，包含样本ID和差异度量值
   - 可选：自动排除该样本或触发人工检查
5. WHEN 评估差异 THEN 系统 SHALL 使用以下指标：
   - 像素级SSIM（结构相似性）≥ 0.95
   - 或像素级MSE ≤ 阈值
   - 或IoU（轮廓交并比）≥ 0.98

#### 4.5 渲染流程

1. WHEN 生成训练数据 THEN 系统 SHALL 使用3D渲染引擎（**Blender**）进行多视图渲染
2. WHEN 渲染整体图像 THEN 系统 SHALL：
   - 使用归一化后的整体模型
   - 从前、后、左、右四个标准视角渲染
   - 支持组合成1/3/4视图拼接格式
3. WHEN 渲染部件图像 THEN 系统 SHALL：
   - 使用归一化后的各部件模型（各自独立归一化）
   - 同样从标准视角渲染多视图图像
4. IF 需要数据增强 THEN 系统 SHALL 支持：
   - 视角扰动（±10°）
   - 光照变化
   - 背景随机化
   - 图像颜色抖动

#### 4.6 数据集组织

1. WHEN 组织数据集 THEN 系统 SHALL 按以下规模准备：
   - 训练集：≥10,000 样本
   - 验证集：≥2,000 样本
   - 测试集：≥2,000 样本
2. WHEN 存储数据 THEN 系统 SHALL 使用以下结构：
   ```
   dataset/
   ├── train/
   │   ├── sample_0001/
   │   │   ├── whole.png           # 整体4视图拼接图（归一化后渲染）
   │   │   ├── part_head.png       # 部件图（归一化后渲染）
   │   │   ├── part_body.png
   │   │   ├── labels.json         # GT变换参数
   │   │   └── validation.png      # 拼合验证图（可选）
   │   └── ...
   ├── val/
   └── test/
   ```
3. WHEN 存储标注 THEN labels.json SHALL 包含：
   ```json
   {
     "model_name": "character_001",
     "whole_normalization": {
       "original_center": [x, y, z],
       "scale_factor": s
     },
     "parts": {
       "head": {
         "translation": [tx, ty, tz],
         "rotation": [qw, qx, qy, qz],
         "scale": [sx, sy, sz],
         "part_normalization": {
           "original_center": [x, y, z],
           "scale_factor": s
         }
       },
       "body": { ... },
       "arm_left": { ... }
     },
     "validation_score": 0.98
   }
   ```

---

### 需求 5：损失函数与训练策略

**用户故事：** 作为一名机器学习研究员，我希望有针对3D变换预测任务设计的损失函数和训练策略，以便有效训练模型达到最优性能。

#### 验收标准

1. WHEN 计算位置损失 THEN 系统 SHALL 使用L1或L2损失衡量预测平移与真实平移的误差
2. WHEN 计算旋转损失 THEN 系统 SHALL 使用四元数geodesic距离损失或角度误差损失
3. WHEN 计算缩放损失 THEN 系统 SHALL 使用L1或对数空间L1损失衡量缩放误差
4. WHEN 组合总损失 THEN 系统 SHALL 支持可配置的损失权重：L_total = w1*L_pos + w2*L_rot + w3*L_scale
5. IF 使用预训练骨干 THEN 系统 SHALL 支持分层学习率（骨干网络使用较小学习率）
6. WHEN 训练模型 THEN 系统 SHALL 支持：
   - 优化器：AdamW
   - 学习率调度：余弦退火 / 阶梯衰减
   - 混合精度训练（FP16/BF16）
   - 梯度裁剪
7. WHEN 监控训练 THEN 系统 SHALL 集成TensorBoard日志记录
8. IF 训练中断 THEN 系统 SHALL 支持从检查点恢复训练

---

### 需求 6：推理与评估

**用户故事：** 作为一名应用开发者，我希望有便捷的推理接口和完善的评估指标，以便在生产环境中使用和评估模型。

#### 验收标准

1. WHEN 进行推理 THEN 系统 SHALL 提供简洁的Python API：
   ```python
   result = model.predict(whole_image, part_image)
   # result = {"translation": [x,y,z], "rotation": [qw,qx,qy,qz], "scale": [sx,sy,sz]}
   ```
2. WHEN 输入不同视图配置 THEN 推理接口 SHALL 自动适配单视图/3视图/4视图输入
3. WHEN 评估模型 THEN 系统 SHALL 计算以下指标：
   - 平均位置误差（MAE，单位：模型坐标单位）
   - 平均旋转误差（度）
   - 平均缩放误差（百分比）
4. IF 需要导出模型 THEN 系统 SHALL 支持ONNX格式导出
5. WHEN 进行性能测试 THEN 系统 SHALL 提供推理延迟和GPU内存占用的benchmark脚本

---

### 需求 7：工程结构与代码质量

**用户故事：** 作为一名开发者，我希望项目有清晰的工程结构和良好的代码质量，以便于维护和扩展。

#### 验收标准

1. WHEN 组织代码 THEN 项目 SHALL 采用以下模块化结构：
   ```
   part_location/
   ├── configs/           # 配置文件（YAML）
   ├── data/              # 数据加载与处理
   │   ├── dataset.py     # PyTorch Dataset
   │   ├── transforms.py  # 数据变换
   │   └── multiview.py   # 多视图处理
   ├── models/            # 模型架构
   │   ├── backbone.py    # DINOv2等骨干网络
   │   ├── fusion.py      # 特征融合模块
   │   ├── head.py        # 变换参数预测头
   │   └── model.py       # 完整模型
   ├── training/          # 训练逻辑
   │   ├── trainer.py     # 训练器
   │   ├── losses.py      # 损失函数
   │   └── scheduler.py   # 学习率调度
   ├── inference/         # 推理逻辑
   ├── evaluation/        # 评估指标
   ├── scripts/           # 运行脚本
   │   ├── train.py
   │   ├── evaluate.py
   │   ├── generate_data.py      # 数据生成脚本
   │   ├── fbx_processor.py      # FBX处理脚本
   │   ├── normalize_model.py    # 模型归一化脚本
   │   └── validate_data.py      # 数据验证脚本
   └── utils/             # 工具函数
   ```
2. WHEN 管理依赖 THEN 项目 SHALL 提供requirements.txt
3. WHEN 配置模型 THEN 系统 SHALL 使用YAML配置文件管理所有超参数
4. WHEN 编写代码 THEN 系统 SHALL 包含类型注解和文档字符串
5. WHEN 使用项目 THEN 系统 SHALL 提供详细的README文档

---

## 技术方案建议

### 推荐模型架构

```
┌─────────────────────────────────────────────────────────────────┐
│                        输入处理层                                │
├─────────────────────────────────────────────────────────────────┤
│  整体图片(1/3/4视图) ──→ [视图分割] ──→ 多个视角图像              │
│  部件图片(1/3/4视图) ──→ [视图分割] ──→ 多个视角图像              │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│                    特征提取层 (DINOv2)                           │
├─────────────────────────────────────────────────────────────────┤
│  整体各视角 ──→ [DINOv2 ViT] ──→ 整体视角特征 [N_whole, D]       │
│  部件各视角 ──→ [DINOv2 ViT] ──→ 部件视角特征 [N_part, D]        │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│                    多视图聚合层                                  │
├─────────────────────────────────────────────────────────────────┤
│  整体视角特征 ──→ [View Aggregation] ──→ 整体融合特征 [D]        │
│  部件视角特征 ──→ [View Aggregation] ──→ 部件融合特征 [D]        │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│                 语义对应层 (Cross-Attention)                     │
├─────────────────────────────────────────────────────────────────┤
│  Query: 部件特征                                                 │
│  Key/Value: 整体特征                                             │
│  Output: 关系特征 [D]                                            │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│                    变换参数预测头                                 │
├─────────────────────────────────────────────────────────────────┤
│  关系特征 ──→ [MLP] ──→ 平移 [3] + 旋转四元数 [4] + 缩放 [3]     │
└─────────────────────────────────────────────────────────────────┘
```

### DINOv2 选型建议

| 模型 | 参数量 | 推理速度 | 适用场景 |
|------|--------|----------|----------|
| ViT-S/14 | 22M | 快 | 轻量部署、实时应用 |
| ViT-B/14 | 86M | 中 | 平衡性能与速度 |
| ViT-L/14 | 300M | 慢 | 追求最佳精度 |

**推荐**：默认使用 ViT-B/14，配置文件支持切换

### 数据生成流程（更新）

```
FBX 3D模型文件（内含sections）
         ↓
    [FBX解析模块]
         ↓
    ┌─────────────────────────────────────────┐
    │ 步骤1: 整体模型归一化                     │
    │  - 计算整体模型边界框                     │
    │  - 一致性缩放到 [-0.5, 0.5]（含padding） │
    │  - 记录归一化参数                         │
    └─────────────────────────────────────────┘
         ↓
    ┌─────────────────────────────────────────┐
    │ 步骤2: 渲染整体模型                       │
    │  - 设置标准相机位置（前后左右）           │
    │  - 渲染4视图拼接图                        │
    └─────────────────────────────────────────┘
         ↓
    ┌─────────────────────────────────────────┐
    │ 步骤3: 对每个section部件                  │
    │  - 提取部件几何体                         │
    │  - 单独归一化到 [-0.5, 0.5]              │
    │  - 计算相对变换参数（T, R, S）           │
    │  - 渲染部件多视图                         │
    └─────────────────────────────────────────┘
         ↓
    ┌─────────────────────────────────────────┐
    │ 步骤4: 验证流程                           │
    │  - 加载各归一化部件                       │
    │  - 应用计算的transform参数                │
    │  - 拼合成完整模型                         │
    │  - 渲染验证图                             │
    │  - 对比与整体图的差异                     │
    │  - IF 差异过大 THEN 标记为错误样本        │
    └─────────────────────────────────────────┘
         ↓
    数据集结构:
    dataset/
    ├── train/
    │   ├── sample_0001/
    │   │   ├── whole.png          # 归一化整体4视图
    │   │   ├── part_head.png      # 归一化部件图
    │   │   ├── labels.json        # GT变换参数+归一化参数
    │   │   └── validation.png     # 拼合验证图
    │   └── ...
    ├── val/
    └── test/
```

---

## 边界情况与技术限制

### 边界情况
1. **视图数量不匹配**：整体为4视图，部件为单视图，需要模型能够处理
2. **部件遮挡**：某些视角下部件可能被遮挡，模型需要从其他视角推断
3. **极端缩放**：部件相对整体极小或极大时的预测稳定性
4. **对称性歧义**：对称物体的旋转可能存在多解
5. **FBX section命名不一致**：不同模型的section命名可能不统一，需要映射处理
6. **部件重叠区域**：某些section可能存在重叠几何体，影响归一化计算

### 技术限制
1. **语义对应的模糊性**：部件与整体的语义对应可能存在歧义
2. **深度信息缺失**：2D图像缺乏深度信息，Z轴位置预测更具挑战
3. **训练数据依赖**：模型性能高度依赖合成数据的质量和多样性
4. **FBX格式兼容性**：不同DCC软件导出的FBX可能存在差异

### 成功标准
1. 位置预测误差 < 5%（相对于模型尺寸）
2. 旋转预测误差 < 10°
3. 缩放预测误差 < 10%
4. 支持单视图/3视图/4视图任意组合输入
5. 推理速度 > 20 FPS（单样本，4视图输入）
6. **数据验证通过率 ≥ 98%**（拼合验证SSIM ≥ 0.95）
